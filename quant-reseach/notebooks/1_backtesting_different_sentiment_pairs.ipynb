{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aa6b0d-41c6-466f-8150-e669a2ceec96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "721ad2af-e1d5-495e-9ed4-e09347c49e80",
   "metadata": {},
   "source": [
    "## Backtesting Sentiment Pairs\n",
    "**Summary:**\n",
    "For rolling average and rolling standard deviation of the lenght 7 days, NLP was calcualted for all possible combinations. A trading fee was assumed 0.0075 (taken from Bitmex). Calculations show that the best pairs are Bots/Whitepaper, Announcement/Bearish, Shilling/Team, and FOMO/Whales. Not surprisingly, increasing fees and window sizes changes to outcome of top performing pairs of topics.\n",
    "Furthermore, NLP of the top performers was plotted on with different windows values (up to 30). It's interesting to see that for some pairs, 7 days for rolling mean and standard deviation is not an optimal window. For example, for whales/FOMO, a window of 24 yields a much higher PNL.\n",
    "Finally a heat map for various moving standard deviation and average windows sizes shows that an optimal value is concentrated within a specific area.\n",
    "In conclusion, due to a very high amount of combinations of windows sizes and sentiment tags, finding the \"best\" pair is hard. Every pair will have its highest NLP concentrated in different areas. Changing a size of one of the windows might change results drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b11e91e-a0be-4398-af4a-fcc174a9c0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../src\")\n",
    "import example_helper as eh\n",
    "import analysis_helper as ah\n",
    "import msgpack\n",
    "import zlib\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc88be4-32db-46d2-a8dd-97ec952f326c",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb191c1-bab2-4483-ab1c-809538516480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the location of the input file\n",
    "filename_augmento_topics = \"../data/example_data/augmento_topics.msgpack.zlib\"\n",
    "filename_augmento_data = \"../data/example_data/augmento_data.msgpack.zlib\"\n",
    "filename_bitmex_data = \"../data/example_data/bitmex_data.msgpack.zlib\"\n",
    "\n",
    "# load the example data\n",
    "all_data = eh.load_example_data(filename_augmento_topics,\n",
    "                             filename_augmento_data,\n",
    "                             filename_bitmex_data)\n",
    "aug_topics, aug_topics_inv, t_aug_data, aug_data, t_price_data, price_data = all_data\n",
    "all_topics = aug_data.T.astype(float)\n",
    "\n",
    "# calculate PNL for a given strategy\n",
    "# if sentiment positive go long, else go short\n",
    "# fees are assumed to be 0.75% (taker fee from BITMEX)\n",
    "\n",
    "def strategy(price_data, signal_a, signal_b, window_1 = 24 * 7, window_2 = 24*7,buy_sell_fee = 0.0075, pnl_0 = 1.0):    \n",
    "    sent_score = ah.nb_calc_sentiment_score_a(signal_a,signal_b,window_1,window_2)\n",
    "    pnl = ah.nb_backtest_a(price_data, sent_score, 1.0, buy_sell_fee)\n",
    "    return pnl\n",
    "\n",
    "# PNL of various moving window size for a given combination of topics\n",
    "def window_combination(price_data,top_a,top_b,end_day_x,end_day_y,start_day_x=0,start_day_y=0,buy_sell_fee=0.0075):\n",
    "    total_comb = np.zeros(shape=(end_day_x,end_day_y))\n",
    "    print(\"Calculating...\")\n",
    "    for i in range(start_day_x,end_day_x):\n",
    "        for j in range(start_day_y,end_day_y):\n",
    "            total_comb[i][j] = strategy(price_data,top_a,top_b,window_1=24*(i+1),window_2=24*(j+1),buy_sell_fee = 0.0075)[-1]\n",
    "    print(\"Done.\")\n",
    "    return total_comb[start_day_x:end_day_x,start_day_y:end_day_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617e60f4-1e58-4370-9311-7f47afb264b7",
   "metadata": {},
   "source": [
    "### Given window size 7 in rolling average and standard deviation, calculate PNL for every possible pair of strategies.\n",
    "It will give 8649 NLP values calculated from 2017 until the beginning of 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e068719-9ea7-49a8-96fe-53da24ba71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each combination of signals, generate PNL for the last period in data\n",
    "total = np.zeros(shape=(93,93))\n",
    "print(\"calculating... might take a minute or two...\")\n",
    "for i in range(0,len(all_topics)):\n",
    "    for j in range(0,len(all_topics)):\n",
    "        sent_score = ah.nb_calc_sentiment_score_a(all_topics[i],all_topics[j],ra_win_size=24*7,std_win_size=24*7)\n",
    "        pnl = ah.nb_backtest_a(price_data, sent_score, 1.0, buy_sell_fee=0.0075)\n",
    "        total[i][j] = pnl[-1]\n",
    "    #print(\"Row \" + str(i+1) + \" out of 93...\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb5798-4e12-4360-9973-e68c1cd75987",
   "metadata": {},
   "source": [
    "### Impossible to see all 8649 values\n",
    "Chose top 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d61f7-6d37-4f9e-a58b-e143d726b15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all PNL in a dataframe\n",
    "data = pd.DataFrame(total).rename(columns=aug_topics,index=aug_topics)\n",
    "# given all combinations of signals, show the combinations that yield the highest PNL\n",
    "c = data.abs()\n",
    "s = c.unstack()\n",
    "so_st = s.sort_values(kind=\"quicksort\")\n",
    "# specify n, a number of top combinations to be shown\n",
    "t = so_st.tail(n=30).index\n",
    "\n",
    "# labels for graphs and tables\n",
    "columns_t = dict((y, x) for x, y in t).keys()\n",
    "rows_t = dict((x, y) for x, y in t).keys()\n",
    "\n",
    "# pick from the dataframes only the pairs of strategies that are within the top list\n",
    "top = data[rows_t].loc[columns_t] \n",
    "\n",
    "so_st.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d38068-0a69-40c0-89dc-91d00d9aa27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43309b11-af9e-4435-9a35-ed6a142c3886",
   "metadata": {},
   "source": [
    "## Heat Map for top 30 pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244635cb-74fd-482a-9dd4-603f67a10b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a sorted dataframe to get highest PNLs in the first rows\n",
    "idx = pd.unique([i[1] for i in np.flip(t.values)])\n",
    "col = pd.unique([i[0] for i in np.flip(t.values)])\n",
    "sorted_df = data[col].loc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2543b0f7-a6f5-478d-8a16-dda79b3f7fb9",
   "metadata": {},
   "source": [
    "### Taking best pairs, plot NLP\n",
    "Heatmap helps to visualilze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42101836-55b9-4f7c-8fdf-afd4d9c8bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a heat map with top 30 PNLs\n",
    "# light colors indicate high, while dark colors low values\n",
    "m = np.array(sorted_df)\n",
    "figure(num=None, figsize=(8, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = sns.heatmap(m, linewidth=0.01, cmap=\"RdYlGn\")\n",
    "ax.set_xticklabels(col, rotation=90)\n",
    "ax.set_yticklabels(idx, rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c958e57-577c-40c8-b8c3-c51c6d50d900",
   "metadata": {},
   "source": [
    "## Testing for different windows sizes\n",
    "Before the backtesting was for only one window size. It's also interesting to see how the strategy would work with different windows sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b69ee-49f3-4e12-aa33-c29f4f8b963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recompute the NLP matrix for the above found combinations for window sizes from 1 to number of days specified\n",
    "number_of_days = 30\n",
    "top_n = 20\n",
    "t_10 = so_st.tail(n=top_n).index\n",
    "empty = np.zeros([top_n, number_of_days])\n",
    "for j in range(len(t_10)):\n",
    "    for days in range(1,(number_of_days+1)):    \n",
    "        a = strategy(price_data,all_topics[aug_topics_inv[t_10[j][1]]],all_topics[aug_topics_inv[t_10[j][0]]],window_1=24*days,window_2=24*days)[-1]\n",
    "        empty[j][days-1] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b4479-3228-4137-b732-d4ad0bd00bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot combinations for different window sizes\n",
    "figure(num=None, figsize=(30, 10), dpi=80)\n",
    "days_a = np.arange(number_of_days)\n",
    "labels = t_10.values\n",
    "cmap = plt.get_cmap('jet')\n",
    "colors = cmap(np.linspace(0, 1.0,20))\n",
    "ax = plt.gca()\n",
    "for i , label, color in zip(empty,labels,colors):\n",
    "    plt.plot(days_a,i,label=label,color=color)\n",
    "    plt.xticks(np.arange(number_of_days), np.arange(1,number_of_days+1))\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Window Size\")\n",
    "    plt.ylabel(\"PnL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20056f42-cb1c-41a2-8429-29937c89ac2a",
   "metadata": {},
   "source": [
    "## Different rolling mean and std window sizes\n",
    "From a chosen pair of topics, compute NLP for various rolling average and rolling std. It's interesting to see, whether the \"optimal\" values are concentrated withing a specific range.\n",
    "\n",
    "### Example for 'Bots' and 'Whitepaper'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76de5b4-2a8b-4def-9852-064c397fcb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify tags\n",
    "ix = 0 # specify startpoint number of rolling mean\n",
    "iy = 10 # specify startpoint of rolling std\n",
    "end_x = 20 # specify endpoint number of rolling mean\n",
    "end_y = 30 # specify endpoint of rolling std\n",
    "topic_a = 'Bots'\n",
    "topic_b = 'Whitepaper'\n",
    "top_b = all_topics[aug_topics_inv[topic_b]]\n",
    "top_a = all_topics[aug_topics_inv[topic_a]]\n",
    "total_s = window_combination(price_data,top_a,top_b,end_x,end_y,start_day_x=ix,start_day_y=iy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91987ea9-6d20-4579-a06e-cb17eed1d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=0.0, dark=1.2, as_cmap=True)\n",
    "figure(num=None, figsize=(10, 7), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = sns.heatmap(total_s, linewidth=0.00, cmap=\"RdYlGn\",yticklabels=np.arange(ix+1,end_x+1),xticklabels=np.arange(iy+1,end_y+1))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640dac05-4e8f-46b1-ac18-11b572f6fd29",
   "metadata": {},
   "source": [
    "#### example for 'Positive' and 'Bearish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ad4ff-fc5d-4779-bdc7-7356eae67915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify tags\n",
    "ix = 0\n",
    "iy = 0\n",
    "end_x = 60\n",
    "end_y = 60\n",
    "topic_a = 'Positive'\n",
    "topic_b = 'Bearish'\n",
    "top_b = all_topics[aug_topics_inv[topic_b]]\n",
    "top_a = all_topics[aug_topics_inv[topic_a]]\n",
    "total_s = window_combination(price_data,top_a,top_b,end_x,end_y,start_day_x=ix,start_day_y=iy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e8c9c6-dfad-4950-b1b6-aa35ace6a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "figure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='black')\n",
    "ax = sns.heatmap(total_s, linewidth=0.00, cmap=\"RdYlGn\",yticklabels=np.arange(ix+1,end_x+1),xticklabels=np.arange(iy+1,end_y+1))\n",
    "ax.set_title('Bearish/Positive')\n",
    "ax.set_ylabel('First Moving Average')\n",
    "ax.set_xlabel('Second Moving Average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcfcec7-70ef-4a26-801f-1f0124c92fbe",
   "metadata": {},
   "source": [
    "### Plotted 4 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5648de5-c31e-417c-a1eb-6da8a3623dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick Topics\n",
    "aug_signal_a = aug_data[:, aug_topics_inv[\"Positive\"]].astype(np.float64)\n",
    "aug_signal_b = aug_data[:, aug_topics_inv[\"Bearish\"]].astype(np.float64)\n",
    "\n",
    "# generate the sentiment score\n",
    "sent_score = ah.nb_calc_sentiment_score_a(aug_signal_a, aug_signal_b, 26*24, 7*24)\n",
    "sent_score1 = ah.nb_calc_sentiment_score_a(aug_signal_a, aug_signal_b, 27*24, 17*24)\n",
    "sent_score2 = ah.nb_calc_sentiment_score_a(aug_signal_a, aug_signal_b, 28*24, 14*24)\n",
    "sent_score3 = ah.nb_calc_sentiment_score_a(aug_signal_a, aug_signal_b, 48*24, 6*24)\n",
    "\n",
    "# define some parameters for the backtest\n",
    "start_pnl = 1.0\n",
    "buy_sell_fee = 0.0075\n",
    "\n",
    "# run the backtest\n",
    "pnl = ah.nb_backtest_a(price_data, sent_score, start_pnl, buy_sell_fee)\n",
    "pnl1 = ah.nb_backtest_a(price_data, sent_score1, start_pnl, buy_sell_fee)\n",
    "pnl2 = ah.nb_backtest_a(price_data, sent_score2, start_pnl, buy_sell_fee)\n",
    "pnl3 = ah.nb_backtest_a(price_data, sent_score3, start_pnl, buy_sell_fee)\n",
    "\n",
    "# set up the figure\n",
    "fig, ax = plt.subplots(2, 1, sharex=True, sharey=False, figsize=(20,10))\n",
    "\n",
    "# initialise some labels for the plot\n",
    "datenum_aug_data = [md.date2num(datetime.datetime.fromtimestamp(el)) for el in t_aug_data]\n",
    "datenum_price_data = [md.date2num(datetime.datetime.fromtimestamp(el)) for el in t_price_data]\n",
    "\n",
    "# plot stuff\n",
    "ax[0].grid(linewidth=0.4)\n",
    "ax[1].grid(linewidth=0.4)\n",
    "\n",
    "ax[0].plot(datenum_price_data, price_data, linewidth=0.5)\n",
    "\n",
    "ax[1].plot(datenum_aug_data, pnl, linewidth=0.5)\n",
    "ax[1].plot(datenum_price_data, pnl1, linewidth=0.5)\n",
    "ax[1].plot(datenum_price_data, pnl2, linewidth=0.5)\n",
    "ax[1].plot(datenum_price_data, pnl3, linewidth=0.5)\n",
    "ax[1].legend((\"A\",\"B\",\"C\",\"D\"))\n",
    "\n",
    "\n",
    "# label axes\n",
    "ax[0].set_ylabel(\"Price\")\n",
    "ax[1].set_ylabel(\"PnL\")\n",
    "ax[0].set_title(\"Profit and Loss.py\")\n",
    "\n",
    "# generate the time axes\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "plt.xticks( rotation=25 )\n",
    "ax[0]=plt.gca()\n",
    "xfmt = md.DateFormatter('%Y-%m-%d')\n",
    "ax[0].xaxis.set_major_formatter(xfmt)\n",
    "\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f028f6f-1d06-412e-b1ac-e7af71e7720b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1d81e5-e1d9-4dbc-8a1d-1de81081dfd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87ba28f-35e5-472d-b549-ec77b6605f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
